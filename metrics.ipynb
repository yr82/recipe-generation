{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUkY4lqpXgiv"
      },
      "source": [
        "## Metrics\n",
        "\n",
        "In order to evaluate and compare the performance of the different methods used, I used nvidia's nemotron-4-340b-reward model that rates the response five scalar values, each corresponding to a HelpSteer2 attribute. I genererated 3 different sets of responses for each method using veriying inputs to generate the average score for each model. The reward model is prompted using the following stucture - \"Give me a recipe for {Title of the recipie generated}\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC9DKQ35ap2V",
        "outputId": "e01e13bd-2866-49a2-fa04-a42ddcaaa22e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.43.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.8)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Downloading openai-1.43.0-py3-none-any.whl (365 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 openai-1.43.0\n"
          ]
        }
      ],
      "source": [
        "! pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vQt4lxqazjE"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9EHqnqDYOxD"
      },
      "source": [
        "## Llama 3.1 8B Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLW7HjqDXXgY",
        "outputId": "c401c57f-ca0f-439c-a193-a40a81ef0373"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChatCompletion(id='83cba44b-3769-46db-8a29-2622d096d245', choices=[Choice(finish_reason='length', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='helpfulness', bytes=None, logprob=1.2109375, top_logprobs=[]), ChatCompletionTokenLogprob(token='correctness', bytes=None, logprob=1.546875, top_logprobs=[]), ChatCompletionTokenLogprob(token='coherence', bytes=None, logprob=3.15625, top_logprobs=[]), ChatCompletionTokenLogprob(token='complexity', bytes=None, logprob=0.88671875, top_logprobs=[]), ChatCompletionTokenLogprob(token='verbosity', bytes=None, logprob=1.328125, top_logprobs=[])], refusal=None), message=[ChatCompletionMessage(content='helpfulness:1.2109375,correctness:1.546875,coherence:3.15625,complexity:0.88671875,verbosity:1.328125', refusal=None, role='assistant', function_call=None, tool_calls=None)])], created=None, model=None, object=None, service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=1, prompt_tokens=138, total_tokens=139))\n"
          ]
        }
      ],
      "source": [
        "# Response 1\n",
        "\n",
        "client = OpenAI(\n",
        "  base_url = \"https://integrate.api.nvidia.com/v1\",\n",
        "  api_key = \"api_key\"\n",
        ")\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"nvidia/nemotron-4-340b-reward\",\n",
        "  messages=[{\"role\":\"user\",\"content\":\"Give me a recipe for Baked Tomatoes\"},{\"role\":\"assistant\",\"content\":\"title: Baked Tomatoes ingredients: [\\\"2 c. tomatoes\\\", \\\"1/2 c. oatmeal\\\", \\\"1/2 c. mozzarella cheese\\\", \\\"2 eggs\\\", \\\"1 can beans\\\"] directions: [\\\"Cut tomatoes in half.\\\", \\\"Mix oatmeal, cheese and eggs.\\\", \\\"Fill tomatoes with mixture.\\\", \\\"Bake at 350\\u00b0 for 30 minutes.\\\", \\\"Top with beans and bake 10 minutes more.\\\"]\"}],\n",
        ")\n",
        "print(completion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "at7u7Ky1ckWa",
        "outputId": "212d64dd-5ede-4374-a324-10977a677f46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helpfulness: 1.2109375\n",
            "Correctness: 1.546875\n",
            "Coherence: 3.15625\n",
            "Complexity: 0.88671875\n",
            "Verbosity: 1.328125\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Accessing the first choice in the ChatCompletion object\n",
        "choice = completion.choices[0]\n",
        "\n",
        "# Extract logprobs for each category\n",
        "helpfulness1 = choice.logprobs.content[0].logprob\n",
        "correctness1 = choice.logprobs.content[1].logprob\n",
        "coherence1 = choice.logprobs.content[2].logprob\n",
        "complexity1 = choice.logprobs.content[3].logprob\n",
        "verbosity1 = choice.logprobs.content[4].logprob\n",
        "\n",
        "# Print the extracted values\n",
        "print(f\"Helpfulness: {helpfulness1}\")\n",
        "print(f\"Correctness: {correctness1}\")\n",
        "print(f\"Coherence: {coherence1}\")\n",
        "print(f\"Complexity: {complexity1}\")\n",
        "print(f\"Verbosity: {verbosity1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cI_n9u2bdUb1",
        "outputId": "165fe621-9536-4493-e1a5-348313fee265"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChatCompletion(id='3f9708b6-639b-4f8c-a511-7976a0c196ab', choices=[Choice(finish_reason='length', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='helpfulness', bytes=None, logprob=1.2421875, top_logprobs=[]), ChatCompletionTokenLogprob(token='correctness', bytes=None, logprob=1.4609375, top_logprobs=[]), ChatCompletionTokenLogprob(token='coherence', bytes=None, logprob=3.109375, top_logprobs=[]), ChatCompletionTokenLogprob(token='complexity', bytes=None, logprob=0.81640625, top_logprobs=[]), ChatCompletionTokenLogprob(token='verbosity', bytes=None, logprob=1.171875, top_logprobs=[])], refusal=None), message=[ChatCompletionMessage(content='helpfulness:1.2421875,correctness:1.4609375,coherence:3.109375,complexity:0.81640625,verbosity:1.171875', refusal=None, role='assistant', function_call=None, tool_calls=None)])], created=None, model=None, object=None, service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=1, prompt_tokens=118, total_tokens=119))\n"
          ]
        }
      ],
      "source": [
        "# Response 2\n",
        "\n",
        "client = OpenAI(\n",
        "  base_url = \"https://integrate.api.nvidia.com/v1\",\n",
        "  api_key = \"api_key\"\n",
        ")\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"nvidia/nemotron-4-340b-reward\",\n",
        "  messages=[{\"role\":\"user\",\"content\":\"Give me a recipe for Turkey Salad\"},{\"role\":\"assistant\",\"content\":\"title: Turkey Salad ingredients: [\\\"1/2 c. diced turkey\\\", \\\"1/2 c. diced tomato\\\", \\\"1/2 c. grape tomato\\\", \\\"1/2 c. turkey\\\", \\\"1/2 c. onion\\\"] directions: [\\\"Mix all ingredients together.\\\", \\\"Serve on lettuce or in a pita bread.\\\"]\"}],\n",
        ")\n",
        "print(completion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soMLfDlLd9Ar",
        "outputId": "a3b10af7-b5a4-4c99-f859-a5d205cb03ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helpfulness: 1.2421875\n",
            "Correctness: 1.4609375\n",
            "Coherence: 3.109375\n",
            "Complexity: 0.81640625\n",
            "Verbosity: 1.171875\n"
          ]
        }
      ],
      "source": [
        "# Accessing the first choice in the ChatCompletion object\n",
        "choice = completion.choices[0]\n",
        "\n",
        "# Extract logprobs for each category\n",
        "helpfulness2 = choice.logprobs.content[0].logprob\n",
        "correctness2 = choice.logprobs.content[1].logprob\n",
        "coherence2 = choice.logprobs.content[2].logprob\n",
        "complexity2 = choice.logprobs.content[3].logprob\n",
        "verbosity2 = choice.logprobs.content[4].logprob\n",
        "\n",
        "# Print the extracted values\n",
        "print(f\"Helpfulness: {helpfulness2}\")\n",
        "print(f\"Correctness: {correctness2}\")\n",
        "print(f\"Coherence: {coherence2}\")\n",
        "print(f\"Complexity: {complexity2}\")\n",
        "print(f\"Verbosity: {verbosity2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cFP4-V4eD1o",
        "outputId": "f5957093-38a3-4ed3-f39c-f9bef2a1a473"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChatCompletion(id='c42c633c-5c4e-4951-9fc8-443b04105b59', choices=[Choice(finish_reason='length', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='helpfulness', bytes=None, logprob=0.80078125, top_logprobs=[]), ChatCompletionTokenLogprob(token='correctness', bytes=None, logprob=1.078125, top_logprobs=[]), ChatCompletionTokenLogprob(token='coherence', bytes=None, logprob=3.046875, top_logprobs=[]), ChatCompletionTokenLogprob(token='complexity', bytes=None, logprob=0.91015625, top_logprobs=[]), ChatCompletionTokenLogprob(token='verbosity', bytes=None, logprob=1.3359375, top_logprobs=[])], refusal=None), message=[ChatCompletionMessage(content='helpfulness:0.80078125,correctness:1.078125,coherence:3.046875,complexity:0.91015625,verbosity:1.3359375', refusal=None, role='assistant', function_call=None, tool_calls=None)])], created=None, model=None, object=None, service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=1, prompt_tokens=142, total_tokens=143))\n"
          ]
        }
      ],
      "source": [
        "# Response 3\n",
        "\n",
        "client = OpenAI(\n",
        "  base_url = \"https://integrate.api.nvidia.com/v1\",\n",
        "  api_key = \"api_key\"\n",
        ")\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"nvidia/nemotron-4-340b-reward\",\n",
        "  messages=[{\"role\":\"user\",\"content\":\"Give me a recipe for Chicken Noodle Casserole\"},{\"role\":\"assistant\",\"content\":\"title: Chicken Noodle Casserole ingredients: [\\\"1 can cream of chicken soup\\\", \\\"1 can cream of celery soup\\\", \\\"1 can cream of mushroom soup\\\", \\\"1 can chicken\\\", \\\"1 can meat\\\", \\\"1 pkg. noodles\\\", \\\"1 pkg. nutty bars\\\", \\\"1 pkg. oatmeal\\\"] directions: [\\\"Mix all ingredients together.\\\", \\\"Put in casserole dish.\\\", \\\"Bake at 350\\u00b0 for 1 hour.\\\"]\"}],\n",
        ")\n",
        "print(completion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCLuSeG1eH4U",
        "outputId": "da47d71b-525d-4ddd-bd5f-082933e86d5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helpfulness: 0.80078125\n",
            "Correctness: 1.078125\n",
            "Coherence: 3.046875\n",
            "Complexity: 0.91015625\n",
            "Verbosity: 1.3359375\n"
          ]
        }
      ],
      "source": [
        "# Accessing the first choice in the ChatCompletion object\n",
        "choice = completion.choices[0]\n",
        "\n",
        "# Extract logprobs for each category\n",
        "helpfulness3 = choice.logprobs.content[0].logprob\n",
        "correctness3 = choice.logprobs.content[1].logprob\n",
        "coherence3 = choice.logprobs.content[2].logprob\n",
        "complexity3 = choice.logprobs.content[3].logprob\n",
        "verbosity3 = choice.logprobs.content[4].logprob\n",
        "\n",
        "# Print the extracted values\n",
        "print(f\"Helpfulness: {helpfulness3}\")\n",
        "print(f\"Correctness: {correctness3}\")\n",
        "print(f\"Coherence: {coherence3}\")\n",
        "print(f\"Complexity: {complexity3}\")\n",
        "print(f\"Verbosity: {verbosity3}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTPYOPUOeu9J",
        "outputId": "50ca1b7c-f681-4e51-a7a4-5e1a3cbc6874"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helpfulness: 1.0846354166666667\n",
            "Correctness: 1.3619791666666667\n",
            "Coherence: 3.1041666666666665\n",
            "Complexity: 0.87109375\n",
            "Verbosity: 1.2786458333333333\n"
          ]
        }
      ],
      "source": [
        "# Calculate score\n",
        "\n",
        "helpfulnessArr = [helpfulness1 + helpfulness2 + helpfulness3]\n",
        "correctnessArr = [correctness1 + correctness2 + correctness3]\n",
        "coherenceArr = [coherence1 + coherence2 + coherence3]\n",
        "complexityArr = [complexity1 + complexity2 + complexity3]\n",
        "verbosityArr = [verbosity1 + verbosity2 + verbosity3]\n",
        "\n",
        "helpfulnessAvg = sum(helpfulnessArr) / 3\n",
        "correctnessAvg = sum(correctnessArr) / 3\n",
        "coherenceAvg = sum(coherenceArr) / 3\n",
        "complexityAvg = sum(complexityArr) / 3\n",
        "verbosityAvg = sum(verbosityArr) / 3\n",
        "\n",
        "print(f\"Helpfulness: {helpfulnessAvg}\")\n",
        "print(f\"Correctness: {correctnessAvg}\")\n",
        "print(f\"Coherence: {coherenceAvg}\")\n",
        "print(f\"Complexity: {complexityAvg}\")\n",
        "print(f\"Verbosity: {verbosityAvg}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5mrYumhgc_8"
      },
      "source": [
        "## T5 Recipe Generation Results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5S_fTVxSiV00",
        "outputId": "613b505d-9aa0-4f7e-da0e-83ad763f2b13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChatCompletion(id='f8af876f-1c8f-4835-a447-4520f988f01a', choices=[Choice(finish_reason='length', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='helpfulness', bytes=None, logprob=0.1669921875, top_logprobs=[]), ChatCompletionTokenLogprob(token='correctness', bytes=None, logprob=0.2255859375, top_logprobs=[]), ChatCompletionTokenLogprob(token='coherence', bytes=None, logprob=2.84375, top_logprobs=[]), ChatCompletionTokenLogprob(token='complexity', bytes=None, logprob=0.53515625, top_logprobs=[]), ChatCompletionTokenLogprob(token='verbosity', bytes=None, logprob=0.6484375, top_logprobs=[])], refusal=None), message=[ChatCompletionMessage(content='helpfulness:0.1669921875,correctness:0.2255859375,coherence:2.84375,complexity:0.53515625,verbosity:0.6484375', refusal=None, role='assistant', function_call=None, tool_calls=None)])], created=None, model=None, object=None, service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=1, prompt_tokens=91, total_tokens=92))\n"
          ]
        }
      ],
      "source": [
        "# Response 1\n",
        "\n",
        "client = OpenAI(\n",
        "  base_url = \"https://integrate.api.nvidia.com/v1\",\n",
        "  api_key = \"api_key\"\n",
        ")\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"nvidia/nemotron-4-340b-reward\",\n",
        "  messages=[{\"role\":\"user\",\"content\":\"Give me a recipe for Roasted Tomatoes\"},{\"role\":\"assistant\",\"content\":\" title: roasted tomatoes ingredients: 1 can whole tomatoes ingredients: 1 jar roasted tomatoes directions: drain tomatoes.-- put in a baking dish.-- bake at 350 for 30 minutes.\"}],\n",
        ")\n",
        "print(completion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSAoFzkOicyf",
        "outputId": "80f2be2a-9db3-4eff-9fc5-d2da9d0d2919"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helpfulness: 0.1669921875\n",
            "Correctness: 0.2255859375\n",
            "Coherence: 2.84375\n",
            "Complexity: 0.53515625\n",
            "Verbosity: 0.6484375\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Accessing the first choice in the ChatCompletion object\n",
        "choice = completion.choices[0]\n",
        "\n",
        "# Extract logprobs for each category\n",
        "helpfulness1 = choice.logprobs.content[0].logprob\n",
        "correctness1 = choice.logprobs.content[1].logprob\n",
        "coherence1 = choice.logprobs.content[2].logprob\n",
        "complexity1 = choice.logprobs.content[3].logprob\n",
        "verbosity1 = choice.logprobs.content[4].logprob\n",
        "\n",
        "# Print the extracted values\n",
        "print(f\"Helpfulness: {helpfulness1}\")\n",
        "print(f\"Correctness: {correctness1}\")\n",
        "print(f\"Coherence: {coherence1}\")\n",
        "print(f\"Complexity: {complexity1}\")\n",
        "print(f\"Verbosity: {verbosity1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkahWcuKizxR",
        "outputId": "ff2a70c1-96de-4a25-e6fa-efb36e08c609"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChatCompletion(id='d0133c35-4f6e-4343-b01e-0710f3718b68', choices=[Choice(finish_reason='length', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='helpfulness', bytes=None, logprob=0.25, top_logprobs=[]), ChatCompletionTokenLogprob(token='correctness', bytes=None, logprob=0.251953125, top_logprobs=[]), ChatCompletionTokenLogprob(token='coherence', bytes=None, logprob=2.484375, top_logprobs=[]), ChatCompletionTokenLogprob(token='complexity', bytes=None, logprob=0.9609375, top_logprobs=[]), ChatCompletionTokenLogprob(token='verbosity', bytes=None, logprob=1.4609375, top_logprobs=[])], refusal=None), message=[ChatCompletionMessage(content='helpfulness:0.25,correctness:0.251953125,coherence:2.484375,complexity:0.9609375,verbosity:1.4609375', refusal=None, role='assistant', function_call=None, tool_calls=None)])], created=None, model=None, object=None, service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=1, prompt_tokens=143, total_tokens=144))\n"
          ]
        }
      ],
      "source": [
        "# Response 2\n",
        "\n",
        "client = OpenAI(\n",
        "  base_url = \"https://integrate.api.nvidia.com/v1\",\n",
        "  api_key = \"api_key\"\n",
        ")\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"nvidia/nemotron-4-340b-reward\",\n",
        "  messages=[{\"role\":\"user\",\"content\":\"Give me a recipe for a simple and delicious swedish cheese and sauce\"},{\"role\":\"assistant\",\"content\":\"title: simple and delicious swedish cheese and sauce ingredients: 1 cup diced_tom, apricot, or apple-- 1 tablespoon or more as desired directions: saute diced aguado in butter or margarine.-- pour sauce over meat of choice.-- i like mine with lots of spices.---- a simple twist to the flavor is to add 1 tablespoon of sugar and the sauce should be thick enough to coat the meat.\"}],\n",
        ")\n",
        "print(completion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1GB8Ajei2DC",
        "outputId": "1c42e54a-edbd-4cbf-d947-ababc6ba7d61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helpfulness: 0.25\n",
            "Correctness: 0.251953125\n",
            "Coherence: 2.484375\n",
            "Complexity: 0.9609375\n",
            "Verbosity: 1.4609375\n"
          ]
        }
      ],
      "source": [
        "# Accessing the first choice in the ChatCompletion object\n",
        "choice = completion.choices[0]\n",
        "\n",
        "# Extract logprobs for each category\n",
        "helpfulness2 = choice.logprobs.content[0].logprob\n",
        "correctness2 = choice.logprobs.content[1].logprob\n",
        "coherence2 = choice.logprobs.content[2].logprob\n",
        "complexity2 = choice.logprobs.content[3].logprob\n",
        "verbosity2 = choice.logprobs.content[4].logprob\n",
        "\n",
        "# Print the extracted values\n",
        "print(f\"Helpfulness: {helpfulness2}\")\n",
        "print(f\"Correctness: {correctness2}\")\n",
        "print(f\"Coherence: {coherence2}\")\n",
        "print(f\"Complexity: {complexity2}\")\n",
        "print(f\"Verbosity: {verbosity2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DKReaykjIJH",
        "outputId": "8df746f4-32ae-4237-87c5-10337b87636a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChatCompletion(id='a0d1f336-fd2e-4080-9879-06cd8eb8414b', choices=[Choice(finish_reason='length', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='helpfulness', bytes=None, logprob=0.173828125, top_logprobs=[]), ChatCompletionTokenLogprob(token='correctness', bytes=None, logprob=0.275390625, top_logprobs=[]), ChatCompletionTokenLogprob(token='coherence', bytes=None, logprob=2.453125, top_logprobs=[]), ChatCompletionTokenLogprob(token='complexity', bytes=None, logprob=1.0625, top_logprobs=[]), ChatCompletionTokenLogprob(token='verbosity', bytes=None, logprob=1.453125, top_logprobs=[])], refusal=None), message=[ChatCompletionMessage(content='helpfulness:0.173828125,correctness:0.275390625,coherence:2.453125,complexity:1.0625,verbosity:1.453125', refusal=None, role='assistant', function_call=None, tool_calls=None)])], created=None, model=None, object=None, service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=1, prompt_tokens=189, total_tokens=190))\n"
          ]
        }
      ],
      "source": [
        "# Response 3\n",
        "\n",
        "client = OpenAI(\n",
        "  base_url = \"https://integrate.api.nvidia.com/v1\",\n",
        "  api_key = \"api_key\"\n",
        ")\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"nvidia/nemotron-4-340b-reward\",\n",
        "  messages=[{\"role\":\"user\",\"content\":\"Give me a recipe for homemade chicken broth\"},{\"role\":\"assistant\",\"content\":\"title: homemade chicken broth recipe ingredients: 8 cups chicken stock-- mrs. v s bbq sauce, to taste directions: place chicken in a stock pot or crock pot.-- pour over the desired amount of water you are going to add to the pot to cover.-- cover and simmer over low heat till chicken is very tender and falling off the bone.-- remove chicken from the stock pot and shred.-- strain the stock into a bowl and skim off any fat.-- bring back to a boil and adjust the amount of chicken stock you ve made.-- reduce heat to low and let simmer until the liquid is reduced to bf, about 15 minutes.-- serve with mashed potatoes and blue cheese salad.\"}],\n",
        ")\n",
        "print(completion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6W8jA3zojLAi",
        "outputId": "f76b5eb4-f063-4ef0-fc65-025fc34edbf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helpfulness: 0.173828125\n",
            "Correctness: 0.275390625\n",
            "Coherence: 2.453125\n",
            "Complexity: 1.0625\n",
            "Verbosity: 1.453125\n"
          ]
        }
      ],
      "source": [
        "# Accessing the first choice in the ChatCompletion object\n",
        "choice = completion.choices[0]\n",
        "\n",
        "# Extract logprobs for each category\n",
        "helpfulness3 = choice.logprobs.content[0].logprob\n",
        "correctness3 = choice.logprobs.content[1].logprob\n",
        "coherence3 = choice.logprobs.content[2].logprob\n",
        "complexity3 = choice.logprobs.content[3].logprob\n",
        "verbosity3 = choice.logprobs.content[4].logprob\n",
        "\n",
        "# Print the extracted values\n",
        "print(f\"Helpfulness: {helpfulness3}\")\n",
        "print(f\"Correctness: {correctness3}\")\n",
        "print(f\"Coherence: {coherence3}\")\n",
        "print(f\"Complexity: {complexity3}\")\n",
        "print(f\"Verbosity: {verbosity3}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSnF-Nf9jQc1",
        "outputId": "91409af3-f10c-4eb9-9f11-5fee7a79e75a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helpfulness: 0.19694010416666666\n",
            "Correctness: 0.2509765625\n",
            "Coherence: 2.59375\n",
            "Complexity: 0.8528645833333334\n",
            "Verbosity: 1.1875\n"
          ]
        }
      ],
      "source": [
        "# Calculate score\n",
        "\n",
        "helpfulnessArr = [helpfulness1 + helpfulness2 + helpfulness3]\n",
        "correctnessArr = [correctness1 + correctness2 + correctness3]\n",
        "coherenceArr = [coherence1 + coherence2 + coherence3]\n",
        "complexityArr = [complexity1 + complexity2 + complexity3]\n",
        "verbosityArr = [verbosity1 + verbosity2 + verbosity3]\n",
        "\n",
        "helpfulnessAvg = sum(helpfulnessArr) / 3\n",
        "correctnessAvg = sum(correctnessArr) / 3\n",
        "coherenceAvg = sum(coherenceArr) / 3\n",
        "complexityAvg = sum(complexityArr) / 3\n",
        "verbosityAvg = sum(verbosityArr) / 3\n",
        "\n",
        "print(f\"Helpfulness: {helpfulnessAvg}\")\n",
        "print(f\"Correctness: {correctnessAvg}\")\n",
        "print(f\"Coherence: {coherenceAvg}\")\n",
        "print(f\"Complexity: {complexityAvg}\")\n",
        "print(f\"Verbosity: {verbosityAvg}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTNi9lcAjSDx"
      },
      "source": [
        "## GPT-4 Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kx6ZKHSuk_Bl"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def remove_markdown(text):\n",
        "    # Remove bold and italics formatting\n",
        "    text = re.sub(r'\\*\\*(.*?)\\*\\*', r'\\1', text)  # **bold**\n",
        "    text = re.sub(r'\\*(.*?)\\*', r'\\1', text)      # *italics* or *bold*\n",
        "    text = re.sub(r'_(.*?)_', r'\\1', text)        # _italics_\n",
        "\n",
        "    # Remove headings (e.g., ### Heading)\n",
        "    text = re.sub(r'#+\\s', '', text)\n",
        "\n",
        "    # Remove inline code and code blocks (backticks)\n",
        "    text = re.sub(r'`(.*?)`', r'\\1', text)        # Inline code\n",
        "    text = re.sub(r'```(.*?)```', r'\\1', text, flags=re.DOTALL)  # Code blocks\n",
        "\n",
        "    # Remove list bullets (-, *, or numbers followed by .)\n",
        "    text = re.sub(r'^\\s*[-*]\\s+', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'^\\s*\\d+\\.\\s+', '', text, flags=re.MULTILINE)\n",
        "\n",
        "    # Remove extra newlines or excess spaces\n",
        "    text = re.sub(r'\\n+', '\\n', text).strip()\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_c1UJldkMia"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"\n",
        "    Sure, I can help with that! Considering the ingredients you have listed, let's make a \"Tomato and Mozzarella Pita Pocket with Creamy Peanut Butter Banana Oatmeal.\" It seems we have some duplicate ingredients (tomatoes listed multiple times), so I'll only count one of each type. Here’s a recipe that incorporates most of your ingredients:\n",
        "\n",
        "    **Tomato and Mozzarella Pita Pocket:**\n",
        "\n",
        "    **Ingredients:**\n",
        "    - 2-3 fresh tomatoes, diced\n",
        "    - 1 cup mozzarella cheese, shredded or in slices\n",
        "    - 1 pita bread, cut in half to form pockets\n",
        "    - 1 egg\n",
        "    - 1 cup sprouted beans or garbanzo beans\n",
        "    - Salt and pepper to taste\n",
        "    - Olive oil (optional)\n",
        "\n",
        "    **Instructions:**\n",
        "    1. **Prep the Ingredients:**\n",
        "        - Dice the tomatoes and sprinkle with a little salt. Let them sit for a few minutes and then drain any excess liquid.\n",
        "        - Rinse the sprouted beans or garbanzo beans (if canned, drain and rinse them).\n",
        "\n",
        "    2. **Cook the Egg:**\n",
        "        - In a small skillet, fry the egg to your liking (sunny-side up, scrambled, etc.). Season with salt and pepper. If you prefer, you can also make a small omelet or cook it hard for easier handling in the pita pocket.\n",
        "\n",
        "    3. **Assemble the Pita Pocket:**\n",
        "        - Carefully open the pita bread pockets.\n",
        "        - Layer the mozzarella cheese inside each pocket.\n",
        "        - Add the diced tomatoes and then the sprouted beans or garbanzo beans.\n",
        "        - Place the cooked egg on top of the tomatoes and beans.\n",
        "        - Optionally, drizzle a little olive oil inside the pita pocket.\n",
        "\n",
        "    4. **Serve:**\n",
        "        - Serve the pita pockets warm or at room temperature as a delicious meal!\n",
        "\n",
        "    **Creamy Peanut Butter Banana Oatmeal:**\n",
        "\n",
        "    **Ingredients:**\n",
        "    - 1 cup oatmeal\n",
        "    - 2 cups milk (or water for a lighter option)\n",
        "    - 1 banana, sliced\n",
        "    - 2 tablespoons creamy peanut butter\n",
        "    - A pinch of salt\n",
        "    - Optional: honey or maple syrup for extra sweetness\n",
        "\n",
        "    **Instructions:**\n",
        "    1. **Cook the Oatmeal:**\n",
        "        - In a medium saucepan, bring the milk (or water) to a boil.\n",
        "        - Stir in the oatmeal and reduce the heat to a simmer.\n",
        "        - Cook according to the package instructions, generally about 5 minutes for quick oats or 10-15 minutes for whole rolled oats, stirring occasionally.\n",
        "\n",
        "    2. **Make it Creamy and Add Flavor:**\n",
        "        - Once the oatmeal is cooked, remove it from the heat.\n",
        "        - Stir in the creamy peanut butter until fully incorporated.\n",
        "        - Add a pinch of salt and mix well for a balanced flavor.\n",
        "\n",
        "    3. **Top with Bananas:**\n",
        "        - Transfer the oatmeal to a bowl.\n",
        "        - Top with slices of banana.\n",
        "        - Optionally, drizzle with honey or maple syrup if desired.\n",
        "\n",
        "    4. **Serve:**\n",
        "        - Serve the oatmeal warm for a comforting and hearty breakfast.\n",
        "\n",
        "    Enjoy your meal!\n",
        "    \"\"\"\n",
        "\n",
        "plain_text = remove_markdown(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cu4ZS18-likh",
        "outputId": "060e7648-c312-405d-abea-e6bdff02566e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChatCompletion(id='e11999f2-0b40-4554-b2d1-2d5114d04ea6', choices=[Choice(finish_reason='length', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='helpfulness', bytes=None, logprob=0.361328125, top_logprobs=[]), ChatCompletionTokenLogprob(token='correctness', bytes=None, logprob=0.64453125, top_logprobs=[]), ChatCompletionTokenLogprob(token='coherence', bytes=None, logprob=2.703125, top_logprobs=[]), ChatCompletionTokenLogprob(token='complexity', bytes=None, logprob=1.4375, top_logprobs=[]), ChatCompletionTokenLogprob(token='verbosity', bytes=None, logprob=2.65625, top_logprobs=[])], refusal=None), message=[ChatCompletionMessage(content='helpfulness:0.361328125,correctness:0.64453125,coherence:2.703125,complexity:1.4375,verbosity:2.65625', refusal=None, role='assistant', function_call=None, tool_calls=None)])], created=None, model=None, object=None, service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=1, prompt_tokens=633, total_tokens=634))\n"
          ]
        }
      ],
      "source": [
        "# Response 1\n",
        "\n",
        "client = OpenAI(\n",
        "  base_url = \"https://integrate.api.nvidia.com/v1\",\n",
        "  api_key = \"api_key\"\n",
        ")\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"nvidia/nemotron-4-340b-reward\",\n",
        "  messages=[{\"role\":\"user\",\"content\":\"Give me a recipe for Tomato and Mozzarella Pita Pocket\"},{\"role\":\"assistant\",\"content\":f\"{plain_text}\"}],\n",
        ")\n",
        "print(completion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULXloDGZllSF",
        "outputId": "beed673e-e0ef-4389-a451-837720a79cfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helpfulness: 0.361328125\n",
            "Correctness: 0.64453125\n",
            "Coherence: 2.703125\n",
            "Complexity: 1.4375\n",
            "Verbosity: 2.65625\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Accessing the first choice in the ChatCompletion object\n",
        "choice = completion.choices[0]\n",
        "\n",
        "# Extract logprobs for each category\n",
        "helpfulness1 = choice.logprobs.content[0].logprob\n",
        "correctness1 = choice.logprobs.content[1].logprob\n",
        "coherence1 = choice.logprobs.content[2].logprob\n",
        "complexity1 = choice.logprobs.content[3].logprob\n",
        "verbosity1 = choice.logprobs.content[4].logprob\n",
        "\n",
        "# Print the extracted values\n",
        "print(f\"Helpfulness: {helpfulness1}\")\n",
        "print(f\"Correctness: {correctness1}\")\n",
        "print(f\"Coherence: {coherence1}\")\n",
        "print(f\"Complexity: {complexity1}\")\n",
        "print(f\"Verbosity: {verbosity1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59Hfsz28l92K"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"\n",
        "    Certainly! Here is a delicious and simple recipe using the ingredients you've listed: \"Turkey Breast with Diced Tomatoes and Grape Tomatoes\".\n",
        "\n",
        "### Turkey Breast with Diced Tomatoes and Grape Tomatoes\n",
        "\n",
        "#### Ingredients:\n",
        "- 2 turkey breasts\n",
        "- 1 can diced tomatoes (14.5 oz)\n",
        "- 1 cup grape tomatoes, halved\n",
        "- 1 medium onion, finely chopped\n",
        "- 2 cloves garlic, minced (optional)\n",
        "- 1 tbsp olive oil\n",
        "- 1 tsp dried oregano\n",
        "- 1 tsp dried basil\n",
        "- Salt and pepper to taste\n",
        "- Fresh parsley, chopped (for garnish)\n",
        "\n",
        "#### Instructions:\n",
        "\n",
        "1. **Prep the Ingredients:**\n",
        "   - Halve the grape tomatoes.\n",
        "   - Finely chop the onion.\n",
        "   - Mince the garlic if you’re using it.\n",
        "\n",
        "2. **Cook the Turkey Breast:**\n",
        "   - Season the turkey breasts with salt and pepper on both sides.\n",
        "   - In a large skillet, heat the olive oil over medium-high heat.\n",
        "   - Add the turkey breasts and cook for about 4-5 minutes per side, until golden brown and cooked through. Remove them from the skillet and set aside.\n",
        "\n",
        "3. **Prepare the Tomato Mixture:**\n",
        "   - In the same skillet, add the chopped onion and garlic (if using). Sauté them for about 2-3 minutes until the onions are translucent and fragrant.\n",
        "   - Add the canned diced tomatoes (with their juice), halved grape tomatoes, dried oregano, and dried basil to the skillet.\n",
        "\n",
        "4. **Simmer the Sauce:**\n",
        "   - Lower the heat to medium and let the tomato mixture simmer for about 10 minutes, stirring occasionally, until the sauce thickens slightly.\n",
        "   - Season the sauce with salt and pepper to taste.\n",
        "\n",
        "5. **Combine and Finish:**\n",
        "   - Return the cooked turkey breasts to the skillet, nestling them into the tomato mixture.\n",
        "   - Spoon some of the tomato sauce over the turkey breasts and let them warm through for about 5 minutes.\n",
        "\n",
        "6. **Garnish and Serve:**\n",
        "   - Garnish with freshly chopped parsley.\n",
        "   - Serve the turkey breasts hot, with the tomato sauce spooned over them.\n",
        "\n",
        "This dish pairs well with rice, pasta, or a side of fresh green vegetables. Enjoy your meal!\n",
        "    \"\"\"\n",
        "\n",
        "plain_text = remove_markdown(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBwO12XTmJ_m",
        "outputId": "e9ee4d29-0cec-4ed5-eaf6-53b6e46b7544"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChatCompletion(id='33635b04-6dd1-432f-b120-18b75d44a8ba', choices=[Choice(finish_reason='length', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='helpfulness', bytes=None, logprob=0.25, top_logprobs=[]), ChatCompletionTokenLogprob(token='correctness', bytes=None, logprob=0.251953125, top_logprobs=[]), ChatCompletionTokenLogprob(token='coherence', bytes=None, logprob=2.484375, top_logprobs=[]), ChatCompletionTokenLogprob(token='complexity', bytes=None, logprob=0.9609375, top_logprobs=[]), ChatCompletionTokenLogprob(token='verbosity', bytes=None, logprob=1.4609375, top_logprobs=[])], refusal=None), message=[ChatCompletionMessage(content='helpfulness:0.25,correctness:0.251953125,coherence:2.484375,complexity:0.9609375,verbosity:1.4609375', refusal=None, role='assistant', function_call=None, tool_calls=None)])], created=None, model=None, object=None, service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=1, prompt_tokens=143, total_tokens=144))\n"
          ]
        }
      ],
      "source": [
        "# Response 2\n",
        "\n",
        "client = OpenAI(\n",
        "  base_url = \"https://integrate.api.nvidia.com/v1\",\n",
        "  api_key = \"api_key\"\n",
        ")\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"nvidia/nemotron-4-340b-reward\",\n",
        "  messages=[{\"role\":\"user\",\"content\":\"Give me a recipe for a simple and delicious swedish cheese and sauce\"},{\"role\":\"assistant\",\"content\":\"title: simple and delicious swedish cheese and sauce ingredients: 1 cup diced_tom, apricot, or apple-- 1 tablespoon or more as desired directions: saute diced aguado in butter or margarine.-- pour sauce over meat of choice.-- i like mine with lots of spices.---- a simple twist to the flavor is to add 1 tablespoon of sugar and the sauce should be thick enough to coat the meat.\"}],\n",
        ")\n",
        "print(completion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0lofh57mMWQ",
        "outputId": "4a8c9779-89d3-459d-dc78-a14e85decab2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helpfulness: 0.25\n",
            "Correctness: 0.251953125\n",
            "Coherence: 2.484375\n",
            "Complexity: 0.9609375\n",
            "Verbosity: 1.4609375\n"
          ]
        }
      ],
      "source": [
        "# Accessing the first choice in the ChatCompletion object\n",
        "choice = completion.choices[0]\n",
        "\n",
        "# Extract logprobs for each category\n",
        "helpfulness2 = choice.logprobs.content[0].logprob\n",
        "correctness2 = choice.logprobs.content[1].logprob\n",
        "coherence2 = choice.logprobs.content[2].logprob\n",
        "complexity2 = choice.logprobs.content[3].logprob\n",
        "verbosity2 = choice.logprobs.content[4].logprob\n",
        "\n",
        "# Print the extracted values\n",
        "print(f\"Helpfulness: {helpfulness2}\")\n",
        "print(f\"Correctness: {correctness2}\")\n",
        "print(f\"Coherence: {coherence2}\")\n",
        "print(f\"Complexity: {complexity2}\")\n",
        "print(f\"Verbosity: {verbosity2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTYsAXMKmdlT"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"\n",
        "    Certainly! Here’s a simple recipe using some of your provided ingredients:\n",
        "\n",
        "**Chicken and Turkey Frank Noodle Stir-Fry**\n",
        "\n",
        "**Ingredients:**\n",
        "- Chicken breast or thighs, sliced (use \"chicken\")\n",
        "- Turkey franks, sliced (use \"turkey_frank\")\n",
        "- Noodles (use \"noodles\")\n",
        "- Sauce of your choice (use \"sauce\")\n",
        "- Eggs (2, beaten)\n",
        "- Chunky vegetables (use \"chnky\"; can be chunky mixed vegetables)\n",
        "- Milk (use \"homo milk\", a splash for the eggs)\n",
        "- Salt and pepper to taste\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1. **Prepare the noodles**:\n",
        "   Cook noodles according to package instructions, then drain and set aside.\n",
        "\n",
        "2. **Cook the chicken and turkey franks**:\n",
        "   - Heat a bit of oil in a large pan or wok over medium-high heat.\n",
        "   - Add the sliced chicken and turkey franks.\n",
        "   - Cook until the chicken is browned and cooked through.\n",
        "\n",
        "3. **Add the vegetables**:\n",
        "   - Add your chunky veggies to the pan.\n",
        "   - Stir-fry until they are tender-crisp.\n",
        "\n",
        "4. **Mix in the eggs**:\n",
        "   - Push the cooked ingredients to one side of the pan.\n",
        "   - Pour beaten eggs with a splash of milk into the empty side.\n",
        "   - Scramble the eggs until fully cooked, then mix everything together.\n",
        "\n",
        "5. **Combine with noodles**:\n",
        "   - Add the cooked noodles to the pan.\n",
        "   - Pour in your chosen sauce.\n",
        "   - Toss everything together until evenly mixed and heated through.\n",
        "\n",
        "6. **Season and serve**:\n",
        "   - Season with salt and pepper to taste.\n",
        "   - Serve hot and enjoy!\n",
        "\n",
        "Feel free to adjust the recipe according to your tastes and add any additional seasonings you prefer\n",
        "    \"\"\"\n",
        "\n",
        "plain_text = remove_markdown(text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64jIPKNtmjFC",
        "outputId": "69a4183e-7fcf-4547-a676-36aabc5f98b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChatCompletion(id='1325a683-2ae0-4455-bb44-d259d818702f', choices=[Choice(finish_reason='length', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='helpfulness', bytes=None, logprob=2.671875, top_logprobs=[]), ChatCompletionTokenLogprob(token='correctness', bytes=None, logprob=2.96875, top_logprobs=[]), ChatCompletionTokenLogprob(token='coherence', bytes=None, logprob=3.59375, top_logprobs=[]), ChatCompletionTokenLogprob(token='complexity', bytes=None, logprob=1.4375, top_logprobs=[]), ChatCompletionTokenLogprob(token='verbosity', bytes=None, logprob=2.0625, top_logprobs=[])], refusal=None), message=[ChatCompletionMessage(content='helpfulness:2.671875,correctness:2.96875,coherence:3.59375,complexity:1.4375,verbosity:2.0625', refusal=None, role='assistant', function_call=None, tool_calls=None)])], created=None, model=None, object=None, service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=1, prompt_tokens=403, total_tokens=404))\n"
          ]
        }
      ],
      "source": [
        "# Response 3\n",
        "\n",
        "client = OpenAI(\n",
        "  base_url = \"https://integrate.api.nvidia.com/v1\",\n",
        "  api_key = \"api_key\"\n",
        ")\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"nvidia/nemotron-4-340b-reward\",\n",
        "  messages=[{\"role\":\"user\",\"content\":\"Give me a recipe for Chicken and Turkey Frank Noodle Stir-Fry\"},{\"role\":\"assistant\",\"content\":f\"title: {plain_text}\"}],\n",
        ")\n",
        "print(completion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvlGBMOYmnQ-",
        "outputId": "d6e14078-095a-4064-a846-6e5d48829fc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helpfulness: 2.671875\n",
            "Correctness: 2.96875\n",
            "Coherence: 3.59375\n",
            "Complexity: 1.4375\n",
            "Verbosity: 2.0625\n"
          ]
        }
      ],
      "source": [
        "# Accessing the first choice in the ChatCompletion object\n",
        "choice = completion.choices[0]\n",
        "\n",
        "# Extract logprobs for each category\n",
        "helpfulness3 = choice.logprobs.content[0].logprob\n",
        "correctness3 = choice.logprobs.content[1].logprob\n",
        "coherence3 = choice.logprobs.content[2].logprob\n",
        "complexity3 = choice.logprobs.content[3].logprob\n",
        "verbosity3 = choice.logprobs.content[4].logprob\n",
        "\n",
        "# Print the extracted values\n",
        "print(f\"Helpfulness: {helpfulness3}\")\n",
        "print(f\"Correctness: {correctness3}\")\n",
        "print(f\"Coherence: {coherence3}\")\n",
        "print(f\"Complexity: {complexity3}\")\n",
        "print(f\"Verbosity: {verbosity3}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZrUZru-mu9i",
        "outputId": "50a0c1b2-8863-4600-dae2-2fc17ea2c5c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helpfulness: 1.0944010416666667\n",
            "Correctness: 1.2884114583333333\n",
            "Coherence: 2.9270833333333335\n",
            "Complexity: 1.2786458333333333\n",
            "Verbosity: 2.0598958333333335\n"
          ]
        }
      ],
      "source": [
        "# Calculate score\n",
        "\n",
        "helpfulnessArr = [helpfulness1 + helpfulness2 + helpfulness3]\n",
        "correctnessArr = [correctness1 + correctness2 + correctness3]\n",
        "coherenceArr = [coherence1 + coherence2 + coherence3]\n",
        "complexityArr = [complexity1 + complexity2 + complexity3]\n",
        "verbosityArr = [verbosity1 + verbosity2 + verbosity3]\n",
        "\n",
        "helpfulnessAvg = sum(helpfulnessArr) / 3\n",
        "correctnessAvg = sum(correctnessArr) / 3\n",
        "coherenceAvg = sum(coherenceArr) / 3\n",
        "complexityAvg = sum(complexityArr) / 3\n",
        "verbosityAvg = sum(verbosityArr) / 3\n",
        "\n",
        "print(f\"Helpfulness: {helpfulnessAvg}\")\n",
        "print(f\"Correctness: {correctnessAvg}\")\n",
        "print(f\"Coherence: {coherenceAvg}\")\n",
        "print(f\"Complexity: {complexityAvg}\")\n",
        "print(f\"Verbosity: {verbosityAvg}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
